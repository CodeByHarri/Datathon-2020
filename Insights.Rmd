---
title: <center><h1>Can electricity consumption patterns tell us anything about the pandemic?</h1></center>
author: 
output:
  html_document: 
    toc: false
    theme: flatly
    toc_float: true
    collapsed: true
    number_sections: false
    toc_depth: 1
editor_options: 
  chunk_output_type: inline
---

<center>
*This report explores electricity consumption patterns within forecasting, demand and behaviours to tackle if data can show us actionable insights.*
</center><br> <!-- New line --> 

1. **Policy Impact**: *2020 vs 2019 Intervential anlaysis & SARIMAX*

2. **Demand & Economics**: *Duck curve & the economy - An analysis into electricity consumption*

3. **Anomalous Behaviours**: *An experimental approach to detect change in production activity*




things left to do: 

* data wrangle australian, and american data into the same format as euro data for hourly data 
* remake the apps to acconomadate for extra data. 

* make an australia only data that by 5min to apply befords law
* look into a victoria only model with weather forecasts for insights app with a business application. 




<center> <h2>**Policy Impact**: 2020 vs 2019 Intervential anlaysis & SARIMAX</h2> </center>

Let's begin with a look at the day to day difference between 2020 and 2019 across the world adjusted for seasonality. Exploring the COVID-19 responses across the world, it is evident that the difference in electricity consumption drastically drops based on the economic policies placed in each country. For example, Italy who began nation wide lockdowns on March 9, saw the immediate impact in electricity consumption over the next couple days. On March 22nd all factories are closed and all nonessential production is halted in Italy causing a further dip consumption difference. This same story can be told with several other countries. Interestingly, Sweden who chose a mitigation strategy still showed very little difference compared to it's Scandinavian neighbours Norway and Denmark who too much more preventitive measures. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
library(ggplot2)
library(tidyverse)
library(gridExtra)
library(dplyr)
library(plotly)
library(itertools)
library(scales)
library(forecast)
library(Rtsne)
```


```{r , echo=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}
worlddata = read.csv("worlddata.csv", header =TRUE, stringsAsFactors = FALSE)
worlddata = worlddata[-1]
worlddata = gather(worlddata, country, load, Australia:US, factor_key=TRUE)
# worlddata = worlddata[order(worlddata$end), ]

worlddata2019 = worlddata[(worlddata$end >= "2019-01-01	" & worlddata$end <= "2019-08-31"),]
worlddata2020 = worlddata[(worlddata$end >= "2020-01-01	" & worlddata$end <= "2020-08-31"),]

worlddata2019$week  = strftime(worlddata2019$end ,"%V")
worlddata2019$day  = strftime(worlddata2019$end, "%u")
worlddata2020$week  = strftime(worlddata2020$end ,"%V")
worlddata2020$day  = strftime(worlddata2020$end, "%u")

worlddatadiff = merge(worlddata2019, worlddata2020, by=c("week","day","country"))
worlddatadiff$diff = (worlddatadiff$load.y / worlddatadiff$load.x)*100 -100
worlddatadiff[worlddatadiff == Inf] <- NA

p <- plot_ly() %>%
  add_trace( data = worlddatadiff, x = ~end.y, y = ~diff, type = 'scatter',
             mode = 'lines', color = ~as.factor(country), alpha = 0.7)
p <- plotly_build(p)

legendItems <- list(Australia = 'legendonly', Austria = 'legendonly', Belgium= 'legendonly', Switzerland= 'legendonly', Germany= 'legendonly', Denmark= 'legendonly', Spain= 'legendonly', France= 'legendonly', UK= 'legendonly', Ireland= 'legendonly', Italy= T, Luxembourg= 'legendonly', Netherlands= 'legendonly', Norway= 'legendonly', Portugal= 'legendonly', Sweden= T, US = 'legendonly')

for(i in seq_along(p$x$data)){
  p$x$data[[i]]$visible <- legendItems[[p$x$data[[i]]$name]]
}

p = p %>% layout(title = 'Energy Consumption Change (%) 2020-2019 Adjusted for Seasonality',
         xaxis = list(title = 'Date'),
         yaxis = list(title = 'Change (%)'))

p = p %>%
    layout(xaxis = list(
        range =
            c(as.numeric(as.POSIXct("2020-01-01", format="%Y-%m-%d"))*1000,
              as.numeric(as.POSIXct("2020-07-30", format="%Y-%m-%d"))*1000),
        type = "date"))

p

```

Intervention analysis aims to accommodate for exigenous forces such as a pandemic with-in it's modelling in time-series analysis with several methods avaliable for trial, such as R packages 'changepoint' and 'mcp'. However, A forecast will a more useful tool in a practical application of electricity consumption. Hence, I've chosen to forecast 2020 and 2019 to compare how predictable electricity consumption is as a micro-study. 

```{r 1, echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}


# # WESTERN EURO DATA DAY
# 
# fr = read.csv("eurodata/fr.csv", header =TRUE, stringsAsFactors = FALSE)
# fr$end = fr$end %>% as.Date()
# fr = aggregate(fr["load"], by=fr["end"], sum)
# fr = fr[1:(length(fr$load)-1),]
# df = fr
# setwd("eurodata/")
# temp = list.files(pattern="*.csv")
# for (i in 1:length(temp)){
#   fr = read.csv(temp[i], header = TRUE, stringsAsFactors = FALSE)
#   fr = na.omit(fr)
#   fr$end = fr$end %>% as.Date()
#   fr = aggregate(fr["load"], by=fr["end"], sum)
#   fr = fr[1:(length(fr$load)-1),]
#   fr[,paste0(temp[i])] = fr$load
#   df = left_join(df, fr, by=c("end"))
# }
# df = df[, -grep("load", colnames(df))]
# colnames(df) = c('end', 'Austria', 'Belgium', 'Switzerland', 'Germany', 'Denmark', 'Spain', 'France', 'UK', 'Ireland', 'Italy', 'Luxembourg', 'Netherlands', 'Norway', 'Portugal','Sweden')
# 
# 
# 
# # AUSTRALIA DATA
# 
# aus = read.csv("ausdata/VIC/PRICE_AND_DEMAND_201501_VIC1.csv", header =TRUE, stringsAsFactors = FALSE)
# aus$SETTLEMENTDATE = aus$SETTLEMENTDATE %>% as.Date()
# aus = aggregate(aus["TOTALDEMAND"], by=aus["SETTLEMENTDATE"], sum)
# aus = aus %>% filter(TOTALDEMAND > 10000)
# 
# temp = list.files("ausdata/VIC/",pattern="*.csv")
# for (i in 1:length(temp)){
#   ausx = read.csv(paste0("ausdata/VIC/",temp[i]), header = TRUE, stringsAsFactors = FALSE)
#   ausx$SETTLEMENTDATE = ausx$SETTLEMENTDATE %>% as.Date()
#   ausx = aggregate(ausx["TOTALDEMAND"], by=ausx["SETTLEMENTDATE"], sum)
#   ausx = ausx %>% filter(TOTALDEMAND >= 10000)
#   aus = rbind(aus, ausx)
# }
# 
# VIC = aus[!duplicated(aus), ]
# 
# aus = read.csv("ausdata/NSW/PRICE_AND_DEMAND_201501_NSW1.csv", header =TRUE, stringsAsFactors = FALSE)
# aus$SETTLEMENTDATE = aus$SETTLEMENTDATE %>% as.Date()
# aus = aggregate(aus["TOTALDEMAND"], by=aus["SETTLEMENTDATE"], sum)
# aus = aus %>% filter(TOTALDEMAND > 10000)
# 
# temp = list.files("ausdata/NSW/",pattern="*.csv")
# for (i in 1:length(temp)){
#   ausx = read.csv(paste0("ausdata/NSW/",temp[i]), header = TRUE, stringsAsFactors = FALSE)
#   ausx$SETTLEMENTDATE = ausx$SETTLEMENTDATE %>% as.Date()
#   ausx = aggregate(ausx["TOTALDEMAND"], by=ausx["SETTLEMENTDATE"], sum)
#   ausx = ausx %>% filter(TOTALDEMAND >= 10000)
#   aus = rbind(aus, ausx)
# }
# NSW = aus[!duplicated(aus), ]
# 
# 
# aus = read.csv("ausdata/QLD/PRICE_AND_DEMAND_201501_QLD1.csv", header =TRUE, stringsAsFactors = FALSE)
# aus$SETTLEMENTDATE = aus$SETTLEMENTDATE %>% as.Date()
# aus = aggregate(aus["TOTALDEMAND"], by=aus["SETTLEMENTDATE"], sum)
# aus = aus %>% filter(TOTALDEMAND > 10000)
# 
# temp = list.files("ausdata/QLD/",pattern="*.csv")
# for (i in 1:length(temp)){
#   ausx = read.csv(paste0("ausdata/QLD/",temp[i]), header = TRUE, stringsAsFactors = FALSE)
#   ausx$SETTLEMENTDATE = ausx$SETTLEMENTDATE %>% as.Date()
#   ausx = aggregate(ausx["TOTALDEMAND"], by=ausx["SETTLEMENTDATE"], sum)
#   ausx = ausx %>% filter(TOTALDEMAND >= 10000)
#   aus = rbind(aus, ausx)
# }
# QLD = aus[!duplicated(aus), ]
# 
# 
# aus = read.csv("ausdata/SA/PRICE_AND_DEMAND_201501_SA1.csv", header =TRUE, stringsAsFactors = FALSE)
# aus$SETTLEMENTDATE = aus$SETTLEMENTDATE %>% as.Date()
# aus = aggregate(aus["TOTALDEMAND"], by=aus["SETTLEMENTDATE"], sum)
# aus = aus %>% filter(TOTALDEMAND > 10000)
# 
# temp = list.files("ausdata/SA/",pattern="*.csv")
# for (i in 1:length(temp)){
#   ausx = read.csv(paste0("ausdata/SA/",temp[i]), header = TRUE, stringsAsFactors = FALSE)
#   ausx$SETTLEMENTDATE = ausx$SETTLEMENTDATE %>% as.Date()
#   ausx = aggregate(ausx["TOTALDEMAND"], by=ausx["SETTLEMENTDATE"], sum)
#   ausx = ausx %>% filter(TOTALDEMAND >= 10000)
#   aus = rbind(aus, ausx)
# }
# SA = aus[!duplicated(aus), ]
# 
# 
# aus = read.csv("ausdata/TAS/PRICE_AND_DEMAND_201501_TAS1.csv", header =TRUE, stringsAsFactors = FALSE)
# aus$SETTLEMENTDATE = aus$SETTLEMENTDATE %>% as.Date()
# aus = aggregate(aus["TOTALDEMAND"], by=aus["SETTLEMENTDATE"], sum)
# aus = aus %>% filter(TOTALDEMAND > 10000)
# 
# temp = list.files("ausdata/TAS/",pattern="*.csv")
# for (i in 1:length(temp)){
#   ausx = read.csv(paste0("ausdata/TAS/",temp[i]), header = TRUE, stringsAsFactors = FALSE)
#   ausx$SETTLEMENTDATE = ausx$SETTLEMENTDATE %>% as.Date()
#   ausx = aggregate(ausx["TOTALDEMAND"], by=ausx["SETTLEMENTDATE"], sum)
#   ausx = ausx %>% filter(TOTALDEMAND >= 10000)
#   aus = rbind(aus, ausx)
# }
# TAS = aus[!duplicated(aus), ]
# 
# remove(aus)
# aus = VIC
# aus$NSW = NSW$TOTALDEMAND
# aus$VIC = VIC$TOTALDEMAND
# aus$TAS = TAS$TOTALDEMAND
# aus$QLD = QLD$TOTALDEMAND
# aus$SA = SA$TOTALDEMAND
# 
# 
# aus = aus[, -grep("TOTALDEMAND", colnames(aus))]
# auswide = gather(aus, state, load, NSW:SA, factor_key=TRUE)
# auswide = auswide[order(auswide$SETTLEMENTDATE), ]
# #saving a state dataframe
# statewide = auswide
# 
# 
# # US DATA
# us = read.csv("usdata/EIA930_BALANCE_2015_Jul_Dec.csv", header =TRUE, stringsAsFactors = FALSE)
# us$Data.Date = us$Data.Date %>% as.Date(format = "%m/%d/%Y")
# us$Demand..MW.=  us$Demand..MW. %>% as.numeric()
# us = aggregate(Demand..MW. ~ Data.Date, data = us, sum)
# 
# temp = list.files("usdata/",pattern="*.csv")
# for (i in 1:length(temp)){
#   usx = read.csv(paste0("usdata/",temp[i]), header = TRUE, stringsAsFactors = FALSE)
#   usx$Data.Date = usx$Data.Date %>% as.Date(format = "%m/%d/%Y")
#   usx$Demand..MW.=  usx$Demand..MW. %>% as.numeric()
#   usx = aggregate(Demand..MW. ~ Data.Date, data = usx, sum)
#   us = rbind(us, usx)
# }
# US = us[!duplicated(us), ]
# US = US[order(US$Data.Date), ]
# colnames(US) = c("end","US")
# 
# # MASTER DATA FRAME
# worlddata = df[-17]
# auswide = aggregate(load ~ SETTLEMENTDATE, data = auswide, sum)
# auswide = auswide[(auswide$SETTLEMENTDATE> "2014-12-31" & auswide$SETTLEMENTDATE< "2020-08-01"),]
# worlddata = add_column(worlddata, Australia = auswide$load, .after = 1) #adds australia
# worlddata = left_join(worlddata, US, by=c("end")) # adds the US 
# 
# 
# write.csv(worlddata, 'worlddata.csv')
# worlddata = read.csv("worlddata.csv", header =TRUE, stringsAsFactors = FALSE)
# 
# worlddata = worlddata[-1]
# 
# worlddata = gather(worlddata, country, load, Australia:US, factor_key=TRUE)
# worlddata = worlddata[order(worlddata$end), ]
# 
# worlddata

```





```{r 2, echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}

# data = worlddata

# country = c('Australia', 'Austria', 'Belgium', 'Switzerland', 'Germany', 'Denmark', 'Spain', 'France', 'UK', 'Ireland', 'Italy', 'Luxembourg', 'Netherlands', 'Norway', 'Portugal','Sweden','US')

# MAKE SARIMA DATA 

# for (country_string in country){print(country_string)
#   # country_string = "US"
# data = worlddata
# data = data %>% filter(country == country_string) 
# data[c("end","load")]
# data
# t20152018 = data[(data$end >= "2015-01-01" & data$end <= "2018-12-31"),]
# t20162019 = data[(data$end >= "2016-01-01" & data$end <= "2019-12-31"),]
# # t20152020 = data
# 
# 
# # Create a daily Date object - helps my work on dates
# inds <- seq(as.Date("2015-01-01"), as.Date("2018-12-31"), by = "day")
# 
# ## Create a time series object
# set.seed(25)
# myts = ts(t20152018$load,
#            start = c(2015, as.numeric(format(inds[1], "%j"))),
#            frequency = 7)
# 
# bestfit <- list(aicc=Inf)
# # Choose the best model by AICc
# for(i in 1:3) {
#   for (j in 1:3){
#     for (k in 1:3){
#     z1 <- fourier(ts(myts, frequency=7), K=i)
#     z2 <- fourier(ts(myts, frequency=365), K=j)
#     z3 <- fourier(ts(myts, frequency=30), K=k)
#     fit <- auto.arima(myts, xreg=cbind(z1, z2, z3), seasonal=F)
#     if(fit$aicc < bestfit$aicc) {
#       bestfit <- list(aicc=fit$aicc, i=i, j=j, k=k, fit=fit)
#     }
#     }
#   }
# }
# 
# # summary(bestfit$fit)
# fcBESTFIT2019 = forecast(bestfit$fit, xreg=cbind(
#                  fourier(ts(myts, frequency=7), K=bestfit$i, h=200),
#                  fourier(ts(myts, frequency=365), K=bestfit$j, h=200),
#                  fourier(ts(myts, frequency=30), K=bestfit$k, h=200)))
# 
# saveRDS(fcBESTFIT2019, file = paste0(country_string,"2019",".rds"))
# fcBESTFIT3 = readRDS(file = "ausdata/bf3.rds")
# Create a daily Date object - helps my work on dates
# inds <- seq(as.Date("2016-01-01"), as.Date("2019-12-31"), by = "day")
# 
# ## Create a time series object
# set.seed(25)
# myts = ts(t20162019$load,
#            start = c(2019, as.numeric(format(inds[1], "%j"))),
#            frequency = 7)
# 
# bestfit <- list(aicc=Inf)
# # Choose the best model by AICc
# for(i in 1:3) {
#   for (j in 1:3){
#     for (k in 1:3){
#     z1 <- fourier(ts(myts, frequency=7), K=i)
#     z2 <- fourier(ts(myts, frequency=365), K=j)
#     z3 <- fourier(ts(myts, frequency=30), K=k)
#     fit <- auto.arima(myts, xreg=cbind(z1, z2, z3), seasonal=F)
#     if(fit$aicc < bestfit$aicc) {
#       bestfit <- list(aicc=fit$aicc, i=i, j=j, k=k, fit=fit)
#     }
#     }
#   }
# }
# 
# # summary(bestfit$fit)
# fcBESTFIT2020 = forecast(bestfit$fit, xreg=cbind(
#                  fourier(ts(myts, frequency=7), K=bestfit$i, h=200),
#                  fourier(ts(myts, frequency=365), K=bestfit$j, h=200),
#                  fourier(ts(myts, frequency=30), K=bestfit$k, h=200)))
# 
# saveRDS(fcBESTFIT2020, file = paste0(country_string,"2020",".rds"))
# }



```




```{r , echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}
# worlddata = gather(worlddata, country, load, Australia:US, factor_key=TRUE)
# worlddata = worlddata[order(worlddata$end), ]

country = c('Australia', 'Austria', 'Belgium', 'Switzerland', 'Germany', 'Denmark', 'Spain', 'France', 'UK', 'Ireland', 'Italy', 'Luxembourg', 'Netherlands', 'Norway', 'Portugal','Sweden','US')


worlddata = read.csv("worlddata.csv", header =TRUE, stringsAsFactors = FALSE)

worlddata = worlddata[-1]

worlddata = gather(worlddata, country, load, Australia:US, factor_key=TRUE)
worlddata = worlddata[order(worlddata$end), ]


worlddata$end = worlddata$end %>% as.Date()

addsarima = function(model,name){
x = seq(as.Date("2019-01-01"), as.Date("2019-07-19"), by = "day")
coun = rep(name,length(x))
model = data.frame(end = x, SARIMAX2019 = model$mean, country = coun)
model$country = model$country %>% as.factor()
worlddata = left_join(worlddata, model, by=c("end","country"))
return(worlddata)
}

Australia19 = readRDS(file = "SARIMAXdata/Australia2019.rds")
Austria19 = readRDS(file = "SARIMAXdata/Austria2019.rds")
Belgium19 = readRDS(file = "SARIMAXdata/Belgium2019.rds")
Switzerland19 = readRDS(file = "SARIMAXdata/Switzerland2019.rds")
Germany19 = readRDS(file = "SARIMAXdata/Germany2019.rds")
Denmark19 = readRDS(file = "SARIMAXdata/Denmark2019.rds")
Spain19 = readRDS(file = "SARIMAXdata/Spain2019.rds")
France19 = readRDS(file = "SARIMAXdata/France2019.rds")
UK19 = readRDS(file = "SARIMAXdata/UK2019.rds")
Ireland19 = readRDS(file = "SARIMAXdata/Ireland2019.rds")
Italy19 = readRDS(file = "SARIMAXdata/Italy2019.rds")
Luxembourg19 = readRDS(file = "SARIMAXdata/Luxembourg2019.rds")
Netherlands19 = readRDS(file = "SARIMAXdata/Netherlands2019.rds")
Norway19 = readRDS(file = "SARIMAXdata/Norway2019.rds")
Portugal19 = readRDS(file = "SARIMAXdata/Portugal2019.rds")
Sweden19 = readRDS(file = "SARIMAXdata/Sweden2019.rds")
worlddata$SARIMAX2019 = addsarima(Australia19,"Australia")$SARIMAX2019
worlddata = left_join(worlddata, addsarima(Austria19,"Austria"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Belgium19,"Belgium"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Switzerland19,"Switzerland"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Germany19,"Germany"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Denmark19,"Denmark"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Spain19,"Spain"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(France19,"France"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(UK19,"UK"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Ireland19,"Ireland"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Italy19,"Italy"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Luxembourg19,"Luxembourg"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Netherlands19,"Netherlands"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Norway19,"Norway"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Portugal19,"Portugal"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]
worlddata = left_join(worlddata, addsarima(Sweden19,"Sweden"), by=c("end","country","load"))
worlddata$SARIMAX2019 = rowSums(worlddata[,c("SARIMAX2019.x", "SARIMAX2019.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:4)]

worlddata[(worlddata$SARIMAX2019 == 0),]$SARIMAX2019 <- NA


addsarima = function(model,name){
x = seq(as.Date("2020-01-01"), as.Date("2020-07-18"), by = "day")
coun = rep(name,length(x))
model = data.frame(end = x, SARIMAX2020 = model$mean, country = coun)
model$country = model$country %>% as.factor()
worlddata = left_join(worlddata, model, by=c("end","country"))
return(worlddata)
}

Australia20 = readRDS(file = "SARIMAXdata/Australia2020.rds")
Austria20 = readRDS(file = "SARIMAXdata/Austria2020.rds")
Belgium20 = readRDS(file = "SARIMAXdata/Belgium2020.rds")
Switzerland20 = readRDS(file = "SARIMAXdata/Switzerland2020.rds")
Germany20 = readRDS(file = "SARIMAXdata/Germany2020.rds")
Denmark20 = readRDS(file = "SARIMAXdata/Denmark2020.rds")
Spain20 = readRDS(file = "SARIMAXdata/Spain2020.rds")
France20 = readRDS(file = "SARIMAXdata/France2020.rds")
UK20 = readRDS(file = "SARIMAXdata/UK2020.rds")
Ireland20 = readRDS(file = "SARIMAXdata/Ireland2020.rds")
Italy20 = readRDS(file = "SARIMAXdata/Italy2020.rds")
Luxembourg20 = readRDS(file = "SARIMAXdata/Luxembourg2020.rds")
Netherlands20 = readRDS(file = "SARIMAXdata/Netherlands2020.rds")
Norway20 = readRDS(file = "SARIMAXdata/Norway2020.rds")
Portugal20 = readRDS(file = "SARIMAXdata/Portugal2020.rds")
Sweden20 = readRDS(file = "SARIMAXdata/Sweden2020.rds")
worlddata$SARIMAX2020 = addsarima(Australia20,"Australia")$SARIMAX2020
worlddata = left_join(worlddata, addsarima(Austria20,"Austria"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Belgium20,"Belgium"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Switzerland20,"Switzerland"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Germany20,"Germany"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Denmark20,"Denmark"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Spain20,"Spain"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(France20,"France"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(UK20,"UK"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Ireland20,"Ireland"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Italy20,"Italy"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Luxembourg20,"Luxembourg"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Netherlands20,"Netherlands"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Norway20,"Norway"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Portugal20,"Portugal"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]
worlddata = left_join(worlddata, addsarima(Sweden20,"Sweden"), by=c("end","country","load","SARIMAX2019"))
worlddata$SARIMAX2020 = rowSums(worlddata[,c("SARIMAX2020.x", "SARIMAX2020.y")], na.rm=TRUE)
worlddata = worlddata[,c(1:5)]

worlddata[(worlddata$SARIMAX2020 == 0),]$SARIMAX2020 <- NA

# worlddata[(worlddata$end >= "2020-01-01"),]

```



```{r, echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}

country = c('Australia', 'Austria', 'Belgium', 'Switzerland', 'Germany', 'Denmark', 'Spain', 'France', 'UK', 'Ireland', 'Italy', 'Luxembourg', 'Netherlands', 'Norway', 'Portugal','Sweden','US')


button_list <- lapply(1:length(country), function(x){
  list(method = "restyle",
       args = list("transforms[0].value", country[x]),
       label = country[x])
})



p <- plot_ly(data = worlddata, x = ~end, y = ~load, type = 'scatter', text = ~end, hoverinfo =~as.factor(end),
             mode = 'lines', alpha = 1, line = list(color = '#06d6a0'), name = paste0("Selected Country"),
             transforms = list( list(
                            type = 'filter',
                            target = ~country,
                            operation = '=',
                            value = unique(worlddata$country)[1]
      ))) %>% layout(
        title = paste0('SARIMAX on Energy Consumption'),
         xaxis = list(title = 'Date'),
         yaxis = list(title = 'MW of Energy'),
    updatemenus = list(
      list(
  xanchor = 'left',
  yanchor = "top",
  pad = list('r'= 0, 't'= 10, 'b' = 10),
  x = 0,
  y = 1.27,
        type = 'dropdown',
        active = 0,
        buttons = button_list
        )
      )
    )
  
# p <- plotly_build(p)


p = p %>% layout(xaxis = list(
        range =
            c(as.numeric(as.POSIXct("2018-11-01", format="%Y-%m-%d"))*1000,
              as.numeric(as.POSIXct("2020-06-30", format="%Y-%m-%d"))*1000),
        type = "date")) 

p = p  %>% layout(xaxis = list(rangeslider = list(type = "date")))

p = p  %>% add_trace(data = worlddata, x = ~end, y = ~SARIMAX2019, type = 'scatter',line=list(color='#e63946',dash='dashed'),
             mode = 'lines', name = 'SARIMAX 2019', alpha = 1)
p = p  %>% add_trace(data = worlddata, x = ~end, y = ~SARIMAX2020, type = 'scatter',line=list(color='#457b9d',dash='dashed'),
             mode = 'lines', name = 'SARIMAX 2020', alpha = 1)
p

# saveRDS(p, file = "worldtime.rds")
# worldtime = readRDS(file = "worldtime.rds")

```

The figure above is a time-series of electricity consumption in each country. with an overlay of a SARIMAX model predicting energy consumption in 2019 vs 2020, having been trained on the previous 4 years worth of data. The appendix outlines the accuracy of these models.The objective of this plot and table is to illustrate the predictability of electricity consumption data during a normal year vs a pandemic enduced year. The change is clearly picked up in the drastic changes in accuracy.

Electricity consumption can be attributed to weather, seasonality, business cycles & base load. Weather and seasonality are present moment indicators unless a weather forecast can be added to the model. The temperature causes one to use heating and cooling measures. Business cycles and base load (level of business activity) can be presumptiously reactive to conditions unlike weather and seasonality which are reactive in the moment. Hence, electricity consumption attributed to business cycles and base load can be a forward looking indicator into economic activity. 



```{r fig.cap="Figure 1: Descriptive Plots" , echo=FALSE, fig.align='left', fig.height=9, fig.width=26, results='hide'}

# fr = read.csv("eurodata/fr.csv", header =TRUE, stringsAsFactors = FALSE)
# fr$end = fr$end %>% as.Date()
# fr = aggregate(fr["load"], by=fr["end"], sum)
# fr = fr[1:(length(fr$load)-1),]
# fr = fr[(fr$end> "2018-01-01	" & fr$end < "2020-07-30"),]
# df = fr
# setwd("eurodata/")
# temp = list.files(pattern="*.csv")
# for (i in 1:length(temp)){
#   fr = read.csv(temp[i], header = TRUE, stringsAsFactors = FALSE)
#   fr = na.omit(fr)
#   fr$end = fr$end %>% as.Date()
#   fr = aggregate(fr["load"], by=fr["end"], sum)
#   fr = fr[1:(length(fr$load)-1),]
#   fr = fr[(fr$end> "2018-01-01	" & fr$end < "2020-07-30"),]
#   fr[,paste0(temp[i])] = fr$load
#   df = left_join(df, fr, by=c("end"))
# }
# df = df[, -grep("load", colnames(df))]
# colnames(df) = c('end', 'Austria', 'Belgium', 'Switzerland', 'Germany', 'Denmark', 'Spain', 'France', 'UK', 'Ireland', 'Italy', 'Luxembourg', 'Netherlands', 'Norway', 'Portugal','Sweden')
# 
# dfwide = gather(df, country, load, Austria:Sweden, factor_key=TRUE)
# 
# write.csv(dfwide, 'widedata.csv')
# dfwide = read.csv("widedata.csv", header =TRUE, stringsAsFactors = FALSE)
# dfwide = dfwide[-1]
```



```{r fig.cap="Figure 1: Descriptive Plots" , echo=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}

# p <- plot_ly() %>%
#   add_trace( data = dfwide, x = ~end, y = ~load, type = 'scatter', 
#              mode = 'lines', color = ~as.factor(country))
# p <- plotly_build(p)
# 
# legendItems <- list(Austria = 'legendonly', Belgium= 'legendonly', Switzerland= 'legendonly', Germany= 'legendonly', Denmark= 'legendonly', Spain= 'legendonly', France= TRUE, UK= 'legendonly', Ireland= 'legendonly', Italy= TRUE, Luxembourg= 'legendonly', Netherlands= 'legendonly', Norway= 'legendonly', Portugal= 'legendonly', Sweden= 'legendonly')
# 
# for(i in seq_along(p$x$data)){
#   p$x$data[[i]]$visible <- legendItems[[p$x$data[[i]]$name]]
# }
# 
# #### LONG FORMAT DATA 
# # fig = plot_ly(df, x = ~end, y = ~Spain, name = "Spain", type = 'scatter', mode = 'lines', colors = "red") 
# # xy.list <- as.list(as.data.frame((df)))
# # for(i in colnames(df)[-1]) { fig <- add_trace(fig, y=xy.list[[i]], x=xy.list[['end']], 
# #                                               name = paste0(i),  type = 'scatter', 
# #                                               mode = 'lines',evaluate = TRUE) }
# 
# p = p %>% layout(title = 'Energy Consumption in Western Europe',
#          xaxis = list(title = 'Time'),
#          yaxis = list(title = 'Energy Consumption (MW)'))
# 
# p = p %>%
#     layout(xaxis = list(
#         range = 
#             c(as.numeric(as.POSIXct("2018-00-01", format="%Y-%m-%d"))*1000,
#               as.numeric(as.POSIXct("2020-07-30", format="%Y-%m-%d"))*1000),
#         type = "date"))
# 
# p

```




```{r fig.cap="Figure 2: Descriptive Plots" , echo=FALSE, fig.align='left', fig.height=9, fig.width=26, results='show'}
# fr = read.csv("eurodata/fr.csv", header =TRUE, stringsAsFactors = FALSE)
# fr = na.omit(fr)
# fr$end = fr$end %>% as.Date()
# fr = aggregate(fr["load"], by=fr["end"], sum)
# fr = fr[1:(length(fr$load)-1),]
# TRAIN2015TO2018 = fr[(fr$end> "2015-01-01	" & fr$end < "2018-12-31"),]
# TEST2017 = fr[(fr$end> "2017-01-01" & fr$end < "2017-07-30"),]
# TEST2018 = fr[(fr$end> "2018-01-01" & fr$end < "2018-07-30"),]
# TEST2019 = fr[(fr$end> "2019-01-01" & fr$end < "2019-07-30"),]
# TRAIN2016TO2019 = fr[(fr$end> "2016-01-01	" & fr$end < "2019-12-31"),]
# TEST2020 = fr[(fr$end> "2020-01-01" & fr$end < "2020-07-30"),]
# 
# x1 = ggplot(fr, aes(x=end, y=load, color = "Electricity Consumed")) +
#   geom_line(size = 2) + theme_minimal() +
#   xlab("Date") + ylab("MW of Electricity Consumed") + scale_x_date(date_labels = "%Y") + ggtitle("FRANCE ELECTRICITY CONSUMPTION")
# 
# fcBESTFIT1 = readRDS(file = "eurodata/bf1.rds")
# fcBESTFIT2 = readRDS(file = "eurodata/bf2.rds")
# p = readRDS(file = "eurodata/p.rds")
# q = readRDS(file = "eurodata/q.rds")

# lay <- rbind(c(1,1,1,1),
#              c(2,2,3,3))
# 
# grid.arrange(x1, p, q, layout_matrix = lay)

# a <- list(
#   text = "TRAINING ON 2015 TO 2018 AND TESTING ON THE FIRST 209 DAYS OF 2019 - FRANCE ELECTRICITY CONSUMPTION",
#   xref = "paper",
#   yref = "paper",
#   yanchor = "bottom",
#   xanchor = "center",
#   align = "center",
#   x = 0.5,
#   y = 1,
#   showarrow = FALSE
# )
# 
# b <- list(
#   text = "TRAINING ON 2016 TO 2019 AND TESTING ON THE FIRST 209 DAYS OF 2020 - FRANCE ELECTRICITY CONSUMPTION
# ",
#   xref = "paper",
#   yref = "paper",
#   yanchor = "bottom",
#   xanchor = "center",
#   align = "center",
#   x = 0.5,
#   y = 1,
#   showarrow = FALSE
# )
# 
# 
# subplot(ggplotly(p)%>%layout(annotations = a), 
#         ggplotly(q)%>%layout(annotations = b), shareY = TRUE)

```





<center> <h2>**Demand & Economics**: Duck curve & the economy - an analysis into electricity consumption</h2> </center>

With this rise in solar energy production anticipation of electricity demand has been on the forefront of utility companies. The duck curve simply is the demand for electricity any given time during the day. The early mornings consist of low energy demands, but as people wake up and busineses begin production the demand rises. Then peaks around sunset before dropping. As you may have guessed the production of energy during the peak hours of the day helps reduce the demand needed. This is evident as the year go on, the dip during mid day drops lower and lower forming a duck like shape. This is more prominent in countries with renewable energy rebates such as Sewden's tax regulation mechanisms and a subsidy scheme. 

There's two critical issues that rise from this. One, as steeper drops in demand occur more rapid increases in the production are needed during peak hours with no sunlight - this poses a serious burden on power infratructure and diminish efficency. 
The second issue is that during days of over production in solar energy, grid managers turn off solar panels to prevent overloading the power grid and throw away extra solar energy. 

The solution is as battery technology evolves, we're able to store energy more efficiently and locally reducing waste while moving away from non-renewables. 












```{r, echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}



# WESTERN EURO DATA HOUR

fr = read.csv("eurodata/fr.csv", header =TRUE, stringsAsFactors = FALSE)
fr = na.omit(fr)
fr$hour = substr(fr$end,11,nchar(fr$end)-12)
fr$year = substr(fr$end,1,nchar(fr$end)-21)
fr  = aggregate(load ~ hour + year, data = fr, mean)
df = fr
setwd("eurodata/")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)){
  fr = read.csv(temp[i], header =TRUE, stringsAsFactors = FALSE)
  fr = na.omit(fr)
  fr$hour = substr(fr$end,11,nchar(fr$end)-12)
  fr$year = substr(fr$end,1,nchar(fr$end)-21)
  fr  = aggregate(load ~ hour + year, data = fr, mean)
  fr[,paste0(temp[i])] = fr$load
  df = left_join(df, fr, by=c("hour","year"))
}
df = df[, -grep("load", colnames(df))]
colnames(df) = c('hour','year', 'Austria', 'Belgium', 'Switzerland', 'Germany', 'Denmark', 'Spain', 'France', 'UK', 'Ireland', 'Italy', 'Luxembourg', 'Netherlands', 'Norway', 'Portugal','Sweden')

eurohourwide = gather(df, country, load, Austria:Sweden, factor_key=TRUE)
eurohourwide = eurohourwide[-3]

country = c('Austria', 'Belgium', 'Switzerland', 'Germany', 'Denmark', 'Spain', 'France', 'UK', 'Ireland', 'Italy', 'Luxembourg', 'Netherlands', 'Norway', 'Portugal','Sweden')

eurohourwide <- eurohourwide[order(eurohourwide$year), ]



# build up interactive element, the filter to the two groups
button_list <- lapply(1:length(country), function(x){
  list(method = "restyle",
       args = list("transforms[0].value", country[x]),
       label = country[x])
})

# fr = read.csv("fr.csv", header =TRUE, stringsAsFactors = FALSE)
# fr = na.omit(fr)
# fr$hour = substr(fr$end,11,nchar(fr$end)-12)
# fr$year = substr(fr$end,1,nchar(fr$end)-21)
# fr  = aggregate(load ~ hour + year, data = fr, mean

p <- plot_ly(data = eurohourwide, x = ~hour, y = ~load, type = 'scatter', text = ~year, hoverinfo =~as.factor(year),
             mode = 'lines', 
             color = ~as.factor(year), alpha = 0.7,
             transforms = list( list(
                            type = 'filter',
                            target = ~country,
                            operation = '=',
                            value = unique(eurohourwide$country)[1]
      ))) %>% layout(
        title = paste0('Intraday Energy Consumption'),
         xaxis = list(title = 'Hour of Day'),
         yaxis = list(title = 'MW of Energy'),
    updatemenus = list(
      list(
  xanchor = 'left',
  yanchor = "top",
  pad = list('r'= 0, 't'= 10, 'b' = 10),
  x = 0,
  y = 1.27,
        type = 'dropdown',
        active = 0,
        buttons = button_list
        )
      )
    )
  
p <- plotly_build(p)

# p = p %>% layout(title = 'Intraday Energy Consumption',
#          xaxis = list(title = 'Time'),
#          yaxis = list(title = 'MW of Energy'))
p 



```



<!-- <div style="text-align: center;"><iframe width="560" height="315" src="https://www.youtube.com/embed/YYLzss58CLs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div> -->


<center> <h2>**Anomalous Behaviours**: An experimental approach to detect change in production activity</h2> </center>





```{r , echo=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}

aus = read.csv("ausdata/VIC/PRICE_AND_DEMAND_201801_VIC1.csv", header =TRUE, stringsAsFactors = FALSE)
temp = list.files("ausdata/VIC/",pattern="*.csv")
for (i in 1:length(temp)){
  ausx = read.csv(paste0("ausdata/VIC/",temp[i]), header = TRUE, stringsAsFactors = FALSE)
  aus = rbind(aus, ausx)
}
aus = aus[c(-1,-5)]
aus$SETTLEMENTDATE = as.POSIXct(aus$SETTLEMENTDATE, format="%Y/%m/%d %H:%M:%S")
aus$SETTLEMENTDATE   = strftime(aus$SETTLEMENTDATE, "%Y:%m:%d %H:00:00") %>% as.character() %>% as.POSIXct(format="%Y:%m:%d %H:%M:%S")

```



```{r , echo=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}

monthdata = function(data,sdate,edata){
  temp = subset(data, SETTLEMENTDATE >= sdate & SETTLEMENTDATE <= edata)
  temp2 = aggregate(RRP~SETTLEMENTDATE,data=temp,sum)
  sub = aggregate(TOTALDEMAND~SETTLEMENTDATE,data=temp,sum)
  sub$RRP = temp2$RRP
  sub$week  = strftime(sub$SETTLEMENTDATE  ,"%V")
  sub$day  = strftime(sub$SETTLEMENTDATE, "%u")
  sub$hour  = strftime(sub$SETTLEMENTDATE, "%H")
  sub = unique(sub)
  cols <- c("week", "day", "hour")
  sub[cols] <- lapply(sub[cols], factor)
  sub$TOTALDEMAND = sub$TOTALDEMAND %>% as.numeric()
  sub$RRP = sub$RRP %>% as.numeric()
  set.seed(42)
  tsne <- Rtsne(sub[-1], check_duplicates = FALSE, pca = TRUE, perplexity=50, theta=0.0, dims=2)
  
  sub = c(tsne$Y %>% as.data.frame(), sub)
  return(sub)
}

```


```{r , echo=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}

plotmonth = function(aus,num_month,end,month){
  set.seed(42)
  a <- list(
  text = month,
  xref = "paper",
  yref = "paper",
  yanchor = "bottom",
  xanchor = "center",
  align = "center",
  x = 0.5,
  y = 1,
  showarrow = FALSE
  )
  
  
  mon2018 = monthdata(aus,sprintf("2018-%s-01",num_month),sprintf("2018-%s-%s",num_month,end))
  mon2019 = monthdata(aus,sprintf("2019-%s-01",num_month),sprintf("2019-%s-%s",num_month,end))
  mon2020 = monthdata(aus,sprintf("2020-%s-01",num_month),sprintf("2020-%s-%s",num_month,end))
  
  mon = c(mon2018, mon2019, mon2020) %>% as.data.frame()
  
  plot_ly( ) %>% 
      add_trace(data = mon, x = ~V1, y = ~V2, type = 'scatter', mode = 'markers', name = '2018', 
                text = ~paste(SETTLEMENTDATE,'</br></br>','TOTAL DEMAND', TOTALDEMAND,'</br>',
                              'RRP: $',RRP,'</br>', 'WEEK', week, '</br>', 'DAY',day,'</br>',
                              'HOUR', hour, '</br>'),
                marker = list(size = ~TOTALDEMAND, sizeref = 4000, sizemode = 'area', color = 'red', line = list(color = 'red'))) %>%
   add_trace(data = mon, x = ~V1.1, y = ~V2.1, type = 'scatter', mode = 'markers', name = '2019', 
                text = ~paste(SETTLEMENTDATE.1,'</br></br>','TOTAL DEMAND', TOTALDEMAND.1,'</br>',
                              'RRP: $',RRP.1,'</br>', 'WEEK', week.1, '</br>', 'DAY',day.1,'</br>',
                              'HOUR', hour.1, '</br>'),
                marker = list(size = ~TOTALDEMAND.1, sizeref = 4000, sizemode = 'area', color = 'blue', line = list(color = 'blue'))) %>%
   add_trace(data = mon, x = ~V1.2, y = ~V2.2, type = 'scatter', mode = 'markers', name = '2020', 
                text = ~paste(SETTLEMENTDATE.2,'</br></br>','TOTAL DEMAND', TOTALDEMAND.2,'</br>',
                              'RRP: $',RRP.2,'</br>', 'WEEK', week.2, '</br>', 'DAY',day.2,'</br>',
                              'HOUR', hour.2, '</br>'),
                marker = list(size = ~TOTALDEMAND.2, sizeref = 4000, sizemode = 'area', color = 'orange', line = list(color = 'orange')))%>% layout(annotations = a)
  # %>% layout(title = month)
}
```


<center> <h3>Monthly Electricity Consumption Patterns in Victoria using t-SNE</h3> </center>
```{r , echo=FALSE, fig.align='left', fig.height=9, fig.width=9, results='show'}

# jan = plotmonth(aus,01,31,'JAN') 
# feb = plotmonth(aus,02,28,'FEB')
# mar = plotmonth(aus,03,31,'MAR')
# apr = plotmonth(aus,04,30,'APR')
# may = plotmonth(aus,05,31,'MAY')
# jun = plotmonth(aus,06,30,'JUN')
# jul = plotmonth(aus,07,31,'JUL')
# aug = plotmonth(aus,08,31,'AUG')
# 
# tsneplot = subplot(jan,feb,mar,apr,may,jun,jul,aug,nrows=4)  %>% layout(showlegend = FALSE)
# saveRDS(tsneplot, file = "tsneplot.rds")


tsneplot= readRDS(file = "tsneplot.rds")
tsneplot

#     add_annotations(
#         text = "MONTHLY ELECTRICITY CONSUMPTION PATTERNS IN VICTORIA",
#         x = 0.5,
#         y = 0,
#         yref = "paper",
#         xref = "paper",
#         xanchor = "center",
#         yanchor = "bottom",
#         yshift = 415,
#         showarrow = FALSE,
#         font = list(size = 15)
#     ) 

```



<!-- <center> <h3>Benfords law on Electricity Load 2020 VS 2019 In Western Europe</h3> </center> -->
```{r, echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}

# library(benford.analysis)
# library(gridExtra)
# 
# 
# euro2020 = eurohourwide %>% filter(year == 2020) 
# euro2019 = eurohourwide %>% filter(year == 2019) 
# 
# # eurodiff$load = euro2020$load - euro2019$load
# 
# trends2020 = benford(euro2020$load, number.of.digits = 1, discrete = T, sign = "positive") 
# trends2019 = benford(euro2019$load, number.of.digits = 1, discrete = T, sign = "positive") 
# # trendsdiff = benford(eurodiff$load, number.of.digits = 1, discrete = T, sign = "positive") 
# 
# 
# trends2020$data = trends2020$data %>% mutate(bl=recode(data.digits, 
#                          `1`=30.1,`2`= 17.6,`3`= 12.5,`4`= 9.7,`5`= 7.9,`6`= 6.7,`7`= 5.8,`8`= 5.1,`9`= 4.6,))
# 
# trends2019$data = trends2019$data %>% mutate(bl=recode(data.digits, 
#                          `1`=30.1,`2`= 17.6,`3`= 12.5,`4`= 9.7,`5`= 7.9,`6`= 6.7,`7`= 5.8,`8`= 5.1,`9`= 4.6,))
# 
# trends2020$s.o.data = trends2020$s.o.data %>% mutate(bl=recode(data.second.order.digits, 
#                          `1`=30.1,`2`= 17.6,`3`= 12.5,`4`= 9.7,`5`= 7.9,`6`= 6.7,`7`= 5.8,`8`= 5.1,`9`= 4.6,))
# trends2019$s.o.data = trends2019$s.o.data %>% mutate(bl=recode(data.second.order.digits, 
#                          `1`=30.1,`2`= 17.6,`3`= 12.5,`4`= 9.7,`5`= 7.9,`6`= 6.7,`7`= 5.8,`8`= 5.1,`9`= 4.6,))
# 
# 
# gg1 = ggplot(trends2020$data,aes(x = data.digits, fill = data.digits)) + 
#   geom_bar(position = "identity", fill = "#90e0ef") + 
#   theme_minimal() + xlab("First Digit")+ geom_line(aes(x = data.digits, y = bl*3),inherit.aes = FALSE, size = 1, color="black", alpha = 0.5, group = 1) + 
#   scale_y_continuous(sec.axis = sec_axis(~. /3))
# # + labs(title="Benfords Law")
# 
# 
# gg2 = ggplot(trends2020$s.o.data,aes(x = data.second.order.digits, fill = data.second.order.digits)) + 
#   geom_bar(position = "identity", fill = "#90e0ef") + 
#   theme_minimal() + xlab("Second Order First Digit") + geom_line(aes(x = data.second.order.digits, y = bl*3),inherit.aes = FALSE, size = 1, color="black", alpha = 0.5, group = 1) + 
#   scale_y_continuous(sec.axis = sec_axis(~. /3))#+ labs(title="Second Order Benfords Law")
# 
# 
# 
# gg3 = ggplot(trends2019$data,aes(x = data.digits, fill = data.digits)) + 
#   geom_bar(position = "identity", fill = "#ade8f4") + 
#   theme_minimal() + xlab("First Digit")+ geom_line(aes(x = data.digits, y = bl*3),inherit.aes = FALSE, size = 1, color="black", alpha = 0.5, group = 1) + 
#   scale_y_continuous(sec.axis = sec_axis(~. /3))
# 
# 
# gg4 = ggplot(trends2019$s.o.data,aes(x = data.second.order.digits, fill = data.second.order.digits)) + 
#   geom_bar(position = "identity", fill = "#ade8f4") + 
#   theme_minimal() + xlab("Second Order First Digit")+ geom_line(aes(x = data.second.order.digits, y = bl*3),inherit.aes = FALSE, size = 1, color="black", alpha = 0.5, group = 1) + 
#   scale_y_continuous(sec.axis = sec_axis(~. /3))
# 
# 
# 
# a <- list(
#   text = "2020 First Order Benfords Law",
#   xref = "paper",
#   yref = "paper",
#   yanchor = "bottom",
#   xanchor = "center",
#   align = "center",
#   x = 0.5,
#   y = 1,
#   showarrow = FALSE
# )
# 
# b <- list(
#   text = "2020 Second Order Benfords Law",
#   xref = "paper",
#   yref = "paper",
#   yanchor = "bottom",
#   xanchor = "center",
#   align = "center",
#   x = 0.5,
#   y = 1,
#   showarrow = FALSE
# )
# 
# c <- list(
#   text = "2019 First Order Benfords Law",
#   xref = "paper",
#   yref = "paper",
#   yanchor = "bottom",
#   xanchor = "center",
#   align = "center",
#   x = 0.5,
#   y = 1,
#   showarrow = FALSE
# )
# 
# d <- list(
#   text = "2019 Second Order Benfords Law",
#   xref = "paper",
#   yref = "paper",
#   yanchor = "bottom",
#   xanchor = "center",
#   align = "center",
#   x = 0.5,
#   y = 1,
#   showarrow = FALSE
# )
# ay <- list(
#   overlaying = "y",
#   side = "right",
#   title = "Ideal Benfords Law"
# )
# 
# 
# subplot(ggplotly(gg1)%>%layout(annotations = a),
#         ggplotly(gg2)%>%layout(annotations = b), 
#         ggplotly(gg3)%>%layout(annotations = c),
#         ggplotly(gg4)%>%layout(annotations = d), 
#         nrows = 2,shareY = TRUE)%>% layout(showlegend = F, yaxis = list(anchor = 'x1'), 
#             yaxis2 = list(showticklabels = T), yaxis4 = list(showticklabels = F), 
#             xaxis = list(showticklabels = F), xaxis2 = list(showticklabels = F)) %>%
#     add_annotations(
#         text = "First Digit in Hourly Load",
#         x = 0.5,
#         y = 0,
#         yref = "paper",
#         xref = "paper",
#         xanchor = "center",
#         yanchor = "bottom",
#         yshift = -35,
#         showarrow = FALSE,
#         font = list(size = 15)
#     ) 
#%>% layout(title= "Benfords Law")

# ggplotly(gg)



# ggplotly(plot(trends))

# trends2020$data = trends2020$data %>% mutate(bl=recode(data.digits, 
#                          `1`=30.1,`2`= 17.6,`3`= 12.5,`4`= 9.7,`5`= 7.9,`6`= 6.7,`7`= 5.8,`8`= 5.1,`9`= 4.6,))
# 
# # euro2020 = eurohourwide %>% filter(year == 2020) %>% select(load)
# gg1 + geom_line(aes(x = data.digits, y = bl*3),inherit.aes = FALSE, size = 1.5, color="black", alpha = 0.5, group = 1) + 
#   scale_y_continuous(sec.axis = sec_axis(~. /3))

```


<!-- <div style="text-align: center;"><iframe width="560" height="315" src="https://www.youtube.com/embed/XXjlR2OK1kM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div> -->

#### VIC DIFF 
```{r , echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}

# aus = read.csv("ausdata/VIC/PRICE_AND_DEMAND_201801_VIC1.csv", header =TRUE, stringsAsFactors = FALSE)
# temp = list.files("ausdata/VIC/",pattern="*.csv")
# for (i in 1:length(temp)){
#   ausx = read.csv(paste0("ausdata/VIC/",temp[i]), header = TRUE, stringsAsFactors = FALSE)
#   aus = rbind(aus, ausx)
# }
# aus = aus[c(-1,-5)]
# aus$SETTLEMENTDATE = as.POSIXct(aus$SETTLEMENTDATE, format="%Y/%m/%d %H:%M:%S")
# aus$SETTLEMENTDATE   = strftime(aus$SETTLEMENTDATE, "%Y:%m:%d %H:00:00") %>% as.character() %>% as.POSIXct(format="%Y:%m:%d %H:%M:%S")
# aus2018 = subset(aus, SETTLEMENTDATE >= "2018-01-01" & SETTLEMENTDATE <= "2018-08-31")
# aus2019 = subset(aus, SETTLEMENTDATE >= "2019-01-01" & SETTLEMENTDATE <= "2019-08-31")
# aus2020 = subset(aus, SETTLEMENTDATE >= "2020-01-01" & SETTLEMENTDATE <= "2020-08-31")

# aus2019$MONTH  = strftime(aus2019$SETTLEMENTDATE ,"%m") %>% as.character()
# aus2019$DAY  = strftime(aus2019$SETTLEMENTDATE, "%Y:%m:%d %H:00:00") %>% as.character() %>% as.POSIXct(format="%Y:%m:%d %H:%M:%S")
# 
# aus2020$MONTH  = strftime(aus2020$SETTLEMENTDATE ,"%m") %>% as.character()
# # aus2020$DAY  = strftime(aus2020$SETTLEMENTDATE, "%Y:%m:%d %H:00:00") %>% as.character() %>% as.POSIXct(format="%Y:%m:%d %H:%M:%S")
# aus2018 = aggregate(TOTALDEMAND~SETTLEMENTDATE,data=aus2018,sum)
# # x1 = aggregate(RRP~DAY+MONTH,data=aus2019,sum)
# aus2019 = aggregate(TOTALDEMAND~SETTLEMENTDATE,data=aus2019,sum)
# # y1 = aggregate(RRP~DAY+MONTH,data=aus2020,sum)
# aus2020 = aggregate(TOTALDEMAND~SETTLEMENTDATE,data=aus2020,sum)

# 
# p = plot_ly() %>%
#   add_trace( data = y1 , x = ~DAY, y = ~RRP, type = 'scatter',
#              mode = 'lines',  color ="#blue", name = '2020 RRP', alpha = 0.7)  %>%
#   add_trace( data = y2 , x = ~DAY, y = ~TOTALDEMAND, type = 'scatter',
#              mode = 'lines',  color ="#red", name = '2020 DEMAND', alpha = 0.7) %>% layout(yaxis = list(type = "log"))
# q = plot_ly() %>%
#   add_trace( data = x1 , x = ~DAY, y = ~RRP, type = 'scatter',
#              mode = 'lines',  color ="#blue", name = '2019 RRP', alpha = 0.7)  %>%
#   add_trace( data = x2 , x = ~DAY, y = ~TOTALDEMAND, type = 'scatter',
#              mode = 'lines',  color ="#red", name = '2019 DEMAND', alpha = 0.7) %>% layout(yaxis = list(type = "log"))
# # 
# # subplot(p,q, nrows=2)
# aus2018$week  = strftime(aus2018$SETTLEMENTDATE  ,"%V")
# aus2018$day  = strftime(aus2018$SETTLEMENTDATE, "%u")
# aus2018$hour  = strftime(aus2018$SETTLEMENTDATE, "%H")
# 
# aus2019$week  = strftime(aus2019$SETTLEMENTDATE  ,"%V")
# aus2019$day  = strftime(aus2019$SETTLEMENTDATE, "%u")
# aus2019$hour  = strftime(aus2019$SETTLEMENTDATE, "%H")
# 
# aus2020$week  = strftime(aus2020$SETTLEMENTDATE  ,"%V")
# aus2020$day  = strftime(aus2020$SETTLEMENTDATE, "%u")
# aus2020$hour  = strftime(aus2020$SETTLEMENTDATE, "%H")
# 
# 
# ausdiff20 = merge(aus2019, aus2020, by=c("week","day","hour"))
# ausdiff20$diff = (ausdiff20$TOTALDEMAND.y / ausdiff20$TOTALDEMAND.x)*100 -100
# ausdiff20[ausdiff20 == Inf] <- NA
# 
# ausdiff19 = merge(aus2018, aus2019, by=c("week","day","hour"))
# ausdiff19$diff = (ausdiff19$TOTALDEMAND.y / ausdiff19$TOTALDEMAND.x)*100 -100
# ausdiff19[ausdiff19 == Inf] <- NA
# 
# # ausdiff[order(ausdiff$SETTLEMENTDATE.y),]
# p = plot_ly() %>%
#   add_trace( data = ausdiff20 , x = ~SETTLEMENTDATE.y, y = ~diff, type = 'scatter',
#              mode = 'lines',  color ="#blue", name = '20-19 DIFF', alpha = 0.7) 
# q = plot_ly() %>%
#   add_trace( data = ausdiff19 , x = ~SETTLEMENTDATE.y, y = ~diff, type = 'scatter',
#              mode = 'lines',  color ="#red", name = '19-18 DIFF', alpha = 0.7)
# 
# subplot(p,q,nrows=2) 

```










```{r , echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}



```




```{r , echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}



```




```{r , echo=FALSE, cache=FALSE, fig.align='left', fig.height=4.5, fig.width=9, results='show'}



```














